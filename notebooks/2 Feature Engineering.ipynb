{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed8ad53-2c0f-48ff-9e8d-9e780505d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d6dc3-dd96-4612-81ed-1c38fd8f14ff",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "* Day of week\n",
    "* Month\n",
    "* Day of month\n",
    "* Quarter of year\n",
    "* Holidays (extracted from the ``holidays`` package)\n",
    "* Identification of peak hours (6:00-9:00, 17:00-21:00)\n",
    "* Time-lagged features\n",
    "* Rolling average\n",
    "* Cyclical Features (cosine and sine of day of month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e8334-6951-4e24-8d8c-7e07ddb123e6",
   "metadata": {},
   "source": [
    "### Get month, day, and day of week from the txn_date column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34ade8c-4b9f-408f-abda-0b8bbcd5677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "\n",
    "def feature_engg1(df_):\n",
    "    \"\"\"\n",
    "    feature_engg1() creates features on day of week, month, quarter\n",
    "    holidays in New York City, rush hour, business day, etc. \n",
    "    \"\"\"\n",
    "    df = df_.copy()\n",
    "    \n",
    "    # Map the weekday names to numbers\n",
    "    day_mapping = {'Sunday': 0, 'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, \n",
    "                   'Thursday': 4, 'Friday': 5, 'Saturday': 6}\n",
    "    df['week_day'] = df['txn_date'].dt.day_name().map(day_mapping)\n",
    "    \n",
    "    # Day\n",
    "    df['day_of_month'] = df['txn_date'].dt.day\n",
    "    df['is_weekend'] = df['week_day'].isin([5, 6]).astype(int)\n",
    "    df['is_monday'] = (df['week_day'] == 0).astype(int)\n",
    "    df['is_friday'] = (df['week_day'] == 4).astype(int)\n",
    "    \n",
    "    # Month\n",
    "    df['month'] = df['txn_date'].dt.month\n",
    "    \n",
    "    # Quarter\n",
    "    df['quarter'] = df['txn_date'].dt.quarter\n",
    "\n",
    "    # Holidays\n",
    "    ny_holidays = holidays.US(years=[2019, 2020, 2021, 2022, 2023, 2024], state='NY')\n",
    "    df['is_holiday'] = df['txn_date'].dt.date.isin(ny_holidays).astype(int)\n",
    "    df['is_holiday_next_day'] = df['is_holiday'].shift(-24)\n",
    "    df['is_holiday_previous_day'] = df['is_holiday'].shift(24)\n",
    "    df['is_long_weekend'] = (\n",
    "        (df['is_holiday'] == 1) & \n",
    "        ((df['week_day'].isin([0, 4, 5, 6])) | \n",
    "         (df['is_holiday_next_day'] == 1) | \n",
    "         (df['is_holiday_previous_day'] == 1))\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Fill next and previous day is holiday (edges of the dataframe)\n",
    "    df[['is_holiday_next_day', 'is_holiday_previous_day']] = df[['is_holiday_next_day', 'is_holiday_previous_day']].fillna(0)\n",
    "\n",
    "    # Peak hours\n",
    "    df['is_rush_hour'] = df['txn_hour'].isin([6, 7, 8, 9, 16, 17, 18, 19, 20]).astype(int)\n",
    "    df['is_business_hour'] = df['txn_hour'].isin(range(9, 18)).astype(int)\n",
    "    df['is_night_hour'] = df['txn_hour'].isin(list(range(22, 24)) + list(range(0, 5))).astype(int)\n",
    "\n",
    "    # Apply the sine and cosine transformations to the txn_hour\n",
    "    df['sin_hour'] = np.sin(2 * np.pi * df['txn_hour'] / 24)\n",
    "    df['cos_hour'] = np.cos(2 * np.pi * df['txn_hour'] / 24)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8e2eb-3cc6-4583-adf8-f03b3aedc874",
   "metadata": {},
   "source": [
    "### Time-Lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea7f981-a8f6-466e-9c4f-068ec994a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_lags_rolling_avg(df, target_col):\n",
    "    \n",
    "    # Create individual lag features\n",
    "    lag_24 = df[target_col].shift(24)\n",
    "    lag_48 = df[target_col].shift(48)\n",
    "    lag_72 = df[target_col].shift(72)\n",
    "    \n",
    "    # Calculate the average of exactly these three points\n",
    "    rolling_avg = pd.concat([lag_24, lag_48, lag_72], axis=1).mean(axis=1)\n",
    "    std = pd.concat([lag_24, lag_48, lag_72], axis=1).std(axis=1)\n",
    "    return rolling_avg, std\n",
    "\n",
    "\n",
    "def weekly_lags_rolling_avg(df, target_col):\n",
    "    # Create individual lag features\n",
    "    lag_w1 = df[target_col].shift(168)\n",
    "    lag_w2 = df[target_col].shift(336)\n",
    "    lag_w3 = df[target_col].shift(504)\n",
    "    lag_w4 = df[target_col].shift(672)\n",
    "    \n",
    "    # Calculate the average of exactly these three points\n",
    "    rolling_avg = pd.concat([lag_w1, lag_w2, lag_w3, lag_w4], axis=1).mean(axis=1)\n",
    "    std = pd.concat([lag_w1, lag_w2, lag_w3, lag_w4], axis=1).std(axis=1)\n",
    "    \n",
    "    return rolling_avg, std\n",
    "    \n",
    "\n",
    "def feature_engg2(df_, target):\n",
    "    \"\"\"\n",
    "    Creates time-lagged features as well as daily and weekly averages.\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        df_\n",
    "        [[\"txn_date\", \"quarter\", \"month\", \"day_of_month\", \"txn_hour\", \n",
    "          \"week_day\", 'is_weekend', 'is_monday', 'is_friday', \n",
    "          'is_holiday', 'is_holiday_next_day','is_holiday_previous_day', 'is_long_weekend', \n",
    "          'is_rush_hour', 'is_business_hour', 'is_night_hour',\n",
    "          'sin_hour', 'cos_hour',\n",
    "          target]]\n",
    "    ).copy()\n",
    "    \n",
    "    # Create lagged features from 24 hours ago\n",
    "    for i in range(24, 48):\n",
    "        df.loc[:, f'lag_{i}'] = df[target].shift(i)\n",
    "\n",
    "    # Create daily lags\n",
    "    lagged_hrs = [48, 72, 96, 120, 144]\n",
    "    for i in lagged_hrs:\n",
    "        df.loc[:, f'lag_{i}'] = df[target].shift(i)\n",
    "\n",
    "    # Create weekly lags\n",
    "    lagged_hrs = [164, 165, 166, 167, 168, 169]\n",
    "    for i in lagged_hrs:\n",
    "        df.loc[:, f'lag_{i}'] = df[target].shift(i)\n",
    "\n",
    "    # More lags based on PACF (around lag 72)\n",
    "    lagged_hrs = [68, 69, 70, 71, 73]\n",
    "    for i in lagged_hrs:\n",
    "        df.loc[:, f'lag_{i}'] = df[target].shift(i)\n",
    "\n",
    "    # More lags based on PACF (around 144)\n",
    "    lagged_hrs = [139, 140, 141, 142, 143, 144, 145]\n",
    "    for i in lagged_hrs:\n",
    "        df.loc[:, f'lag_{i}'] = df[target].shift(i)\n",
    "\n",
    "    # More lags based on PACF (around 168)\n",
    "    lagged_hrs = [164, 165, 166, 167, 168, 169]\n",
    "    for i in lagged_hrs:\n",
    "        df.loc[:, f'lag_{i}'] = df[target].shift(i)\n",
    "\n",
    "    # Daily lags\n",
    "    df['rolling_avg_24_48_72_lags'], df[\"std_24_48_72_lags\"] = daily_lags_rolling_avg(df, target)\n",
    "    \n",
    "    # Weekly lags\n",
    "    df['rolling_avg_w1-w4_lags'], df[\"std_w1-w4_lags\"] = weekly_lags_rolling_avg(df, target)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1cefe-3084-48b9-ae87-557c878f0a8a",
   "metadata": {},
   "source": [
    "# Main part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d870606-86e8-41e8-8ecd-c8504bb3f9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brooklyn\n",
      "\tnum_txns_Yellow Taxi Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Green Taxi Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_For-Hire Vehicle Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Uber\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Lyft\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "Manhattan\n",
      "\tnum_txns_Yellow Taxi Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Green Taxi Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_For-Hire Vehicle Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Uber\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Lyft\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "Queens\n",
      "\tnum_txns_Yellow Taxi Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Green Taxi Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_For-Hire Vehicle Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Uber\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Lyft\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "Staten Island\n",
      "\tnum_txns_Yellow Taxi Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Green Taxi Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_For-Hire Vehicle Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Uber\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Lyft\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "Bronx\n",
      "\tnum_txns_Yellow Taxi Trip Records\n",
      "\t\tDates with missing data: txn_date\n",
      "2019-03-10    23\n",
      "2020-03-08    23\n",
      "2021-03-14    23\n",
      "2023-03-12    23\n",
      "2024-03-10    23\n",
      "Name: txn_hour, dtype: int64\n",
      "\tnum_txns_Green Taxi Trip Records\n",
      "\t\tDates with missing data: txn_date\n",
      "2019-03-10    23\n",
      "2020-03-08    23\n",
      "2021-03-14    23\n",
      "2023-03-12    23\n",
      "2024-03-10    23\n",
      "Name: txn_hour, dtype: int64\n",
      "\tnum_txns_For-Hire Vehicle Trip Records\n",
      "\t\tDates with missing data: txn_date\n",
      "2019-03-10    23\n",
      "2020-03-08    23\n",
      "2021-03-14    23\n",
      "2023-03-12    23\n",
      "2024-03-10    23\n",
      "Name: txn_hour, dtype: int64\n",
      "\tnum_txns_Uber\n",
      "\t\tDates with missing data: txn_date\n",
      "2019-03-10    23\n",
      "2020-03-08    23\n",
      "2021-03-14    23\n",
      "2023-03-12    23\n",
      "2024-03-10    23\n",
      "Name: txn_hour, dtype: int64\n",
      "\tnum_txns_Lyft\n",
      "\t\tDates with missing data: txn_date\n",
      "2019-03-10    23\n",
      "2020-03-08    23\n",
      "2021-03-14    23\n",
      "2023-03-12    23\n",
      "2024-03-10    23\n",
      "Name: txn_hour, dtype: int64\n",
      "EWR\n",
      "\tnum_txns_Yellow Taxi Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Green Taxi Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_For-Hire Vehicle Trip Records\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Uber\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "\tnum_txns_Lyft\n",
      "\t\tDates with missing data: Series([], Name: txn_hour, dtype: int64)\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "boroughs = [\"Brooklyn\", \"Manhattan\", \"Queens\", \"Staten Island\", \"Bronx\", \"EWR\"]\n",
    "target = [\n",
    "    'num_txns_Yellow Taxi Trip Records', 'num_txns_Green Taxi Trip Records', \n",
    "    'num_txns_For-Hire Vehicle Trip Records','num_txns_Uber', 'num_txns_Lyft'\n",
    "]\n",
    "\n",
    "for borough in boroughs:\n",
    "    print(borough)\n",
    "    for ride_type in target:\n",
    "        print(f\"\\t{ride_type}\")\n",
    "        \n",
    "        # Read the data of the specific borough\n",
    "        df = pd.read_parquet(rf\"..\\data\\final_processed\\{borough} - all.parquet.gz\")\n",
    "        df = df.set_index(\"timestamp_hour\")\n",
    "        df['txn_date'] = pd.to_datetime(df['txn_date'])\n",
    "        df = df[\n",
    "            (df['txn_date'] >= '2019-02-01') & (df['txn_date'] <= '2024-12-31')\n",
    "        ]\n",
    "        df['txn_month'] = df['txn_date'].apply(lambda x: pd.Timestamp(year=x.year, month=x.month, day=1))\n",
    "    \n",
    "        # Checking if the data is complete\n",
    "        grouped = df.groupby('txn_date')['txn_hour'].nunique()\n",
    "        print(f\"\\t\\tDates with missing data: {grouped[grouped < 24]}\")\n",
    "    \n",
    "        # Feature Engineering\n",
    "        df = feature_engg1(df)\n",
    "        df = feature_engg2(df, ride_type)\n",
    "\n",
    "        # Export the data to a parquet file\n",
    "        # Define base directory\n",
    "        base_dir = os.path.join(\"..\", \"data\", \"with_feature_engineering\", borough)\n",
    "        \n",
    "        # Create the folder\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "        \n",
    "        # Define the file name\n",
    "        file_name = f\"{borough}_{ride_type.replace(' Trip Records', '')}_features.parquet.gz\"\n",
    "        \n",
    "        # Save the DataFrame\n",
    "        df.to_parquet(os.path.join(base_dir, file_name), compression=\"gzip\")\n",
    "        \n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ddea705-1d17-4ffc-8539-f055ba509aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_date</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>txn_hour</th>\n",
       "      <th>week_day</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_monday</th>\n",
       "      <th>is_friday</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_139</th>\n",
       "      <th>lag_140</th>\n",
       "      <th>lag_141</th>\n",
       "      <th>lag_142</th>\n",
       "      <th>lag_143</th>\n",
       "      <th>lag_145</th>\n",
       "      <th>rolling_avg_24_48_72_lags</th>\n",
       "      <th>std_24_48_72_lags</th>\n",
       "      <th>rolling_avg_w1-w4_lags</th>\n",
       "      <th>std_w1-w4_lags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp_hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-01 00:00:00</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 01:00:00</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 02:00:00</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 03:00:00</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 04:00:00</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      txn_date  quarter  month  day_of_month  txn_hour  \\\n",
       "timestamp_hour                                                           \n",
       "2019-02-01 00:00:00 2019-02-01        1      2             1         0   \n",
       "2019-02-01 01:00:00 2019-02-01        1      2             1         1   \n",
       "2019-02-01 02:00:00 2019-02-01        1      2             1         2   \n",
       "2019-02-01 03:00:00 2019-02-01        1      2             1         3   \n",
       "2019-02-01 04:00:00 2019-02-01        1      2             1         4   \n",
       "\n",
       "                     week_day  is_weekend  is_monday  is_friday  is_holiday  \\\n",
       "timestamp_hour                                                                \n",
       "2019-02-01 00:00:00         5           1          0          0           0   \n",
       "2019-02-01 01:00:00         5           1          0          0           0   \n",
       "2019-02-01 02:00:00         5           1          0          0           0   \n",
       "2019-02-01 03:00:00         5           1          0          0           0   \n",
       "2019-02-01 04:00:00         5           1          0          0           0   \n",
       "\n",
       "                     ...  lag_139  lag_140  lag_141  lag_142  lag_143  \\\n",
       "timestamp_hour       ...                                                \n",
       "2019-02-01 00:00:00  ...      NaN      NaN      NaN      NaN      NaN   \n",
       "2019-02-01 01:00:00  ...      NaN      NaN      NaN      NaN      NaN   \n",
       "2019-02-01 02:00:00  ...      NaN      NaN      NaN      NaN      NaN   \n",
       "2019-02-01 03:00:00  ...      NaN      NaN      NaN      NaN      NaN   \n",
       "2019-02-01 04:00:00  ...      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "                     lag_145  rolling_avg_24_48_72_lags  std_24_48_72_lags  \\\n",
       "timestamp_hour                                                               \n",
       "2019-02-01 00:00:00      NaN                        NaN                NaN   \n",
       "2019-02-01 01:00:00      NaN                        NaN                NaN   \n",
       "2019-02-01 02:00:00      NaN                        NaN                NaN   \n",
       "2019-02-01 03:00:00      NaN                        NaN                NaN   \n",
       "2019-02-01 04:00:00      NaN                        NaN                NaN   \n",
       "\n",
       "                     rolling_avg_w1-w4_lags  std_w1-w4_lags  \n",
       "timestamp_hour                                               \n",
       "2019-02-01 00:00:00                     NaN             NaN  \n",
       "2019-02-01 01:00:00                     NaN             NaN  \n",
       "2019-02-01 02:00:00                     NaN             NaN  \n",
       "2019-02-01 03:00:00                     NaN             NaN  \n",
       "2019-02-01 04:00:00                     NaN             NaN  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/with_feature_engineering/Brooklyn/Brooklyn_num_txns_For-Hire Vehicle_features.parquet.gz\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
